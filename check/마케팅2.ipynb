{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e46a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "import bs4\n",
    "from collections import Counter\n",
    "import konlpy\n",
    "from konlpy.tag import Hannanum\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576795cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('D:/marketing/data1.xlsx')\n",
    "a = list(data['실검'])\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "for i, v in enumerate(a):\n",
    "    b.append([v,i])\n",
    "    if i % 7 == 6:\n",
    "        c.append(max(b)[1])\n",
    "        b = []\n",
    "for i in c:\n",
    "    d.append(str(data.loc[i, '날짜'])[:10].replace('-',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5b66d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '20210225'),\n",
       " (1, '20210304'),\n",
       " (2, '20210312'),\n",
       " (3, '20210323'),\n",
       " (4, '20210325'),\n",
       " (5, '20210407'),\n",
       " (6, '20210412'),\n",
       " (7, '20210417'),\n",
       " (8, '20210426'),\n",
       " (9, '20210505'),\n",
       " (10, '20210506'),\n",
       " (11, '20210513'),\n",
       " (12, '20210524'),\n",
       " (13, '20210530'),\n",
       " (14, '20210607'),\n",
       " (15, '20210610'),\n",
       " (16, '20210618'),\n",
       " (17, '20210628'),\n",
       " (18, '20210703'),\n",
       " (19, '20210709'),\n",
       " (20, '20210716'),\n",
       " (21, '20210725'),\n",
       " (22, '20210802'),\n",
       " (23, '20210808'),\n",
       " (24, '20210812'),\n",
       " (25, '20210823'),\n",
       " (26, '20210826'),\n",
       " (27, '20210902'),\n",
       " (28, '20210911'),\n",
       " (29, '20210916'),\n",
       " (30, '20210923'),\n",
       " (31, '20211005'),\n",
       " (32, '20211009'),\n",
       " (33, '20211018'),\n",
       " (34, '20211025'),\n",
       " (35, '20211028'),\n",
       " (36, '20211105'),\n",
       " (37, '20211111'),\n",
       " (38, '20211123'),\n",
       " (39, '20211129'),\n",
       " (40, '20211204'),\n",
       " (41, '20211214'),\n",
       " (42, '20211216'),\n",
       " (43, '20211226'),\n",
       " (44, '20220101'),\n",
       " (45, '20220109'),\n",
       " (46, '20220116'),\n",
       " (47, '20220126'),\n",
       " (48, '20220201'),\n",
       " (49, '20220207'),\n",
       " (50, '20220211'),\n",
       " (51, '20220222'),\n",
       " (52, '20220224'),\n",
       " (53, '20220307'),\n",
       " (54, '20220310'),\n",
       " (55, '20220317'),\n",
       " (56, '20220324'),\n",
       " (57, '20220404'),\n",
       " (58, '20220410'),\n",
       " (59, '20220416'),\n",
       " (60, '20220421'),\n",
       " (61, '20220502'),\n",
       " (62, '20220507'),\n",
       " (63, '20220518'),\n",
       " (64, '20220523'),\n",
       " (65, '20220529'),\n",
       " (66, '20220608'),\n",
       " (67, '20220615'),\n",
       " (68, '20220616'),\n",
       " (69, '20220629'),\n",
       " (70, '20220630'),\n",
       " (71, '20220708'),\n",
       " (72, '20220719'),\n",
       " (73, '20220725'),\n",
       " (74, '20220802'),\n",
       " (75, '20220808'),\n",
       " (76, '20220811'),\n",
       " (77, '20220819'),\n",
       " (78, '20220830'),\n",
       " (79, '20220905'),\n",
       " (80, '20220911'),\n",
       " (81, '20220918'),\n",
       " (82, '20220926'),\n",
       " (83, '20221004'),\n",
       " (84, '20221006'),\n",
       " (85, '20221015'),\n",
       " (86, '20221025'),\n",
       " (87, '20221030'),\n",
       " (88, '20221103'),\n",
       " (89, '20221115'),\n",
       " (90, '20221117'),\n",
       " (91, '20221129'),\n",
       " (92, '20221203'),\n",
       " (93, '20221213'),\n",
       " (94, '20221219'),\n",
       " (95, '20221228'),\n",
       " (96, '20221230'),\n",
       " (97, '20230109'),\n",
       " (98, '20230117'),\n",
       " (99, '20230125'),\n",
       " (100, '20230129'),\n",
       " (101, '20230204'),\n",
       " (102, '20230209'),\n",
       " (103, '20230220'),\n",
       " (104, '20230227'),\n",
       " (105, '20230302'),\n",
       " (106, '20230310'),\n",
       " (107, '20230316'),\n",
       " (108, '20230323'),\n",
       " (109, '20230404'),\n",
       " (110, '20230411'),\n",
       " (111, '20230417'),\n",
       " (112, '20230420'),\n",
       " (113, '20230428'),\n",
       " (114, '20230510')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = []\n",
    "for n, y in enumerate(d):\n",
    "    e.append((n,y))\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65557868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fd8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger=Hannanum()\n",
    "check = ['경향신문','국민일보','동아일보','문화일보','서울신문','세계일보','조선일보','중앙일보','한겨레','한국일보','뉴스1','뉴시스','연합뉴스','채널A','한국경제TV','JTBC','KBS','MBC','MBN','SBS','TV조선','YTN','노컷뉴스','데일리안','미디어오늘','아이뉴스24','오마이뉴스','프레시안','디지털데일리','디지털타임스','블로터','전자신문','ZDNet Korea']\n",
    "stopwords = ['단독','논란','구독','뉴스','채널','네이버','연합뉴스','금지','재배포','오후','오전','이후','이날','사진','콘텐츠','영상편집','영상취재','기자','만원','때문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 0 y = 20210225\n",
      "newsEnd\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14328\\1573155859.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "n = 1 y = 20210304\n",
      "newsEnd\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14328\\1573155859.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "n = 2 y = 20210312\n",
      "newsEnd\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14328\\1573155859.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    }
   ],
   "source": [
    "for n, y in e:\n",
    "    print(\"n =\", n, \"y =\", y)\n",
    "    url = \"https://news.naver.com/main/ranking/popularDay.naver?date=\" + y\n",
    "    html = urllib.request.urlopen(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    bs_obj = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    div = bs_obj.findAll(\"div\", {\"class\":\"rankingnews_box\"})\n",
    "\n",
    "    k=1\n",
    "    data=[]\n",
    "    col = ['No','Publisher','Rank','Title','URL','Contents']\n",
    "\n",
    "    for i in div:\n",
    "        publisher = i.find(\"strong\", {\"class\":\"rankingnews_name\"})\n",
    "        if publisher.text in check:\n",
    "            ul = i.find(\"ul\", {\"class\":\"rankingnews_list\"})\n",
    "            lis = ul.findAll(\"li\")\n",
    "            for j in lis:\n",
    "                em_tag = j.find(\"em\")\n",
    "                a_tag = j.find(\"a\")\n",
    "\n",
    "                if (a_tag != None) and (em_tag != None):\n",
    "                    article_url = a_tag['href']\n",
    "                    news=urllib.request.urlopen(article_url)\n",
    "                    news_obj = bs4.BeautifulSoup(news, \"html.parser\")\n",
    "                    body = news_obj.find(\"div\", {\"id\":\"newsct_article\",\"class\":\"newsct_article _article_body\"})\n",
    "                    if body == None:\n",
    "                        body = news_obj.find(\"div\", {\"id\":\"newsEndContents\",\"class\":\"news_end\"})\n",
    "                        print(\"newsEnd\")\n",
    "                        if body == None:\n",
    "                            print('ERROR')\n",
    "                            continue\n",
    "                    contents = body.text.replace('\\n','')\n",
    "                    row = [k, publisher.text, em_tag.text, a_tag.text, article_url, contents]\n",
    "                    data.append(row)\n",
    "                    k += 1\n",
    "            time.sleep(1)\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = col)\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR\")\n",
    "    else:\n",
    "        print(\"Done\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    text = df[df['Publisher'].isin(check)]['Contents']\n",
    "    text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    tokenized_data_filtered=[]\n",
    "    for j in text_filtered:\n",
    "        temp = tagger.nouns(j)\n",
    "        temp = [word for word in temp if len(word)>1]  ## 두글자 이상이면 포함, 리스트 함축\n",
    "        temp = [word for word in temp if word not in stopwords]\n",
    "        tokenized_data_filtered.append(temp)\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    tokens=[]\n",
    "    for k in tokenized_data_filtered:\n",
    "        tokens.extend(k)\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    num_top_tokens=100\n",
    "    counted_tokens=Counter(tokens)\n",
    "    top_keywords=dict(counted_tokens.most_common(num_top_tokens))\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    globals()['tk_df{}'.format(n)] = pd.DataFrame(list(top_keywords.items()), columns=['keywords','freq'])\n",
    "    globals()['tk_df{}'.format(n)].to_csv('D:/marketing/data5/tk_df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    time.sleep(600)\n",
    "    print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0031c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 14 y = 20210607\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 15 y = 20210610\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 16 y = 20210618\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 17 y = 20210628\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 18 y = 20210703\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 19 y = 20210709\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 20 y = 20210716\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20784\\2886238681.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 21 y = 20210725\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (a_tag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (em_tag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     24\u001b[0m     article_url \u001b[38;5;241m=\u001b[39m a_tag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 25\u001b[0m     news\u001b[38;5;241m=\u001b[39m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     news_obj \u001b[38;5;241m=\u001b[39m bs4\u001b[38;5;241m.\u001b[39mBeautifulSoup(news, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     body \u001b[38;5;241m=\u001b[39m news_obj\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewsct_article\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewsct_article _article_body\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "for n, y in e[21:]:\n",
    "    print(\"n =\", n, \"y =\", y)\n",
    "    url = \"https://news.naver.com/main/ranking/popularDay.naver?date=\" + y\n",
    "    html = urllib.request.urlopen(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    bs_obj = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    div = bs_obj.findAll(\"div\", {\"class\":\"rankingnews_box\"})\n",
    "\n",
    "    k=1\n",
    "    data=[]\n",
    "    col = ['No','Publisher','Rank','Title','URL','Contents']\n",
    "\n",
    "    for i in div:\n",
    "        publisher = i.find(\"strong\", {\"class\":\"rankingnews_name\"})\n",
    "        if publisher.text in check:\n",
    "            ul = i.find(\"ul\", {\"class\":\"rankingnews_list\"})\n",
    "            lis = ul.findAll(\"li\")\n",
    "            for j in lis:\n",
    "                em_tag = j.find(\"em\")\n",
    "                a_tag = j.find(\"a\")\n",
    "\n",
    "                if (a_tag != None) and (em_tag != None):\n",
    "                    article_url = a_tag['href']\n",
    "                    news=urllib.request.urlopen(article_url)\n",
    "                    news_obj = bs4.BeautifulSoup(news, \"html.parser\")\n",
    "                    body = news_obj.find(\"div\", {\"id\":\"newsct_article\",\"class\":\"newsct_article _article_body\"})\n",
    "                    if body == None:\n",
    "                        body = news_obj.find(\"div\", {\"id\":\"newsEndContents\",\"class\":\"news_end\"})\n",
    "                        print(\"newsEnd\")\n",
    "                        if body == None:\n",
    "                            print('ERROR1')\n",
    "                            continue\n",
    "                    contents = body.text.replace('\\n','')\n",
    "                    row = [k, publisher.text, em_tag.text, a_tag.text, article_url, contents]\n",
    "                    data.append(row)\n",
    "                    k += 1\n",
    "            time.sleep(1)\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = col)\n",
    "    df.to_csv('D:/marketing/data5/df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR2\")\n",
    "    else:\n",
    "        print(\"Done\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    text = df[df['Publisher'].isin(check)]['Contents']\n",
    "    text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    tokenized_data_filtered=[]\n",
    "    for j in text_filtered:\n",
    "        temp = tagger.nouns(j)\n",
    "        temp = [word for word in temp if len(word)>1]  ## 두글자 이상이면 포함, 리스트 함축\n",
    "        temp = [word for word in temp if word not in stopwords]\n",
    "        tokenized_data_filtered.append(temp)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    tokens=[]\n",
    "    for k in tokenized_data_filtered:\n",
    "        tokens.extend(k)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    num_top_tokens=100\n",
    "    counted_tokens=Counter(tokens)\n",
    "    top_keywords=dict(counted_tokens.most_common(num_top_tokens))\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    tk_df = pd.DataFrame(list(top_keywords.items()), columns=['keywords','freq'])\n",
    "    tk_df.to_csv('D:/marketing/data5/tk_df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    print(\"sleep 10min\")\n",
    "    time.sleep(600)\n",
    "    print('#'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b079a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a7da0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, '20210312'), (6, '20210412')]\n"
     ]
    }
   ],
   "source": [
    "f = []\n",
    "for n, y in e:\n",
    "    if n in [2, 6]:\n",
    "        f.append((n, y))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03b907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b432d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 51 y = 20220222\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 52 y = 20220224\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 53 y = 20220307\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 54 y = 20220310\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 55 y = 20220317\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 56 y = 20220324\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 57 y = 20220404\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 58 y = 20220410\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 59 y = 20220416\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 60 y = 20220421\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 61 y = 20220502\n",
      "ERROR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_19984\\2511201532.py:51: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 10min\n",
      "##############################\n",
      "n = 62 y = 20220507\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (a_tag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (em_tag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     25\u001b[0m     article_url \u001b[38;5;241m=\u001b[39m a_tag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m     news\u001b[38;5;241m=\u001b[39m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     news_obj \u001b[38;5;241m=\u001b[39m bs4\u001b[38;5;241m.\u001b[39mBeautifulSoup(news, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     body \u001b[38;5;241m=\u001b[39m news_obj\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewsct_article\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewsct_article _article_body\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "for n, y in e[51:]:\n",
    "    print(\"n =\", n, \"y =\", y)\n",
    "    url = \"https://news.naver.com/main/ranking/popularDay.naver?date=\" + y\n",
    "    headers = {'User-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "    html = requests.get(url, headers = headers)\n",
    "    time.sleep(10)\n",
    "\n",
    "    bs_obj = bs4.BeautifulSoup(html.content, \"html.parser\")\n",
    "    div = bs_obj.findAll(\"div\", {\"class\":\"rankingnews_box\"})\n",
    "\n",
    "    k=1\n",
    "    data=[]\n",
    "    col = ['No','Publisher','Rank','Title','URL','Contents']\n",
    "\n",
    "    for i in div:\n",
    "        publisher = i.find(\"strong\", {\"class\":\"rankingnews_name\"})\n",
    "        if publisher.text in check:\n",
    "            ul = i.find(\"ul\", {\"class\":\"rankingnews_list\"})\n",
    "            lis = ul.findAll(\"li\")\n",
    "            for j in lis:\n",
    "                em_tag = j.find(\"em\")\n",
    "                a_tag = j.find(\"a\")\n",
    "\n",
    "                if (a_tag != None) and (em_tag != None):\n",
    "                    article_url = a_tag['href']\n",
    "#                    news=urllib.request.urlopen(article_url)\n",
    "#                    news_obj = bs4.BeautifulSoup(news, \"html.parser\")\n",
    "#                     body = news_obj.find(\"div\", {\"id\":\"newsct_article\",\"class\":\"newsct_article _article_body\"})\n",
    "#                     if body == None:\n",
    "#                         body = news_obj.find(\"div\", {\"id\":\"newsEndContents\",\"class\":\"news_end\"})\n",
    "#                         print(\"newsEnd\")\n",
    "#                         if body == None:\n",
    "#                             print('ERROR1')\n",
    "#                             continue\n",
    "#                     contents = body.text.replace('\\n','')\n",
    "                     row = [k, publisher.text, em_tag.text, a_tag.text, article_url, contents]\n",
    "#                     data.append(row)\n",
    "#                     k += 1\n",
    "#             time.sleep(random.randint(1, 4))\n",
    "#         time.sleep(random.randint(1, 4))\n",
    "\n",
    "    df = pd.DataFrame(data, columns = col)\n",
    "    df.to_csv('D:/marketing/data5/df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR2\")\n",
    "    else:\n",
    "        print(\"Done\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    text = df[df['Publisher'].isin(check)]['Contents']\n",
    "    text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    tokenized_data_filtered=[]\n",
    "    for j in text_filtered:\n",
    "        temp = tagger.nouns(j)\n",
    "        temp = [word for word in temp if len(word)>1]  ## 두글자 이상이면 포함, 리스트 함축\n",
    "        temp = [word for word in temp if word not in stopwords]\n",
    "        tokenized_data_filtered.append(temp)\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    tokens=[]\n",
    "    for k in tokenized_data_filtered:\n",
    "        tokens.extend(k)\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    num_top_tokens=100\n",
    "    counted_tokens=Counter(tokens)\n",
    "    top_keywords=dict(counted_tokens.most_common(num_top_tokens))\n",
    "\n",
    "    #time.sleep(5)\n",
    "\n",
    "    tk_df = pd.DataFrame(list(top_keywords.items()), columns=['keywords','freq'])\n",
    "    tk_df.to_csv('D:/marketing/data5/tk_df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    print(\"sleep 10min\")\n",
    "    time.sleep(600)\n",
    "    t = random.randint(30, 60)\n",
    "    time.sleep(t)\n",
    "    print('#'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6c6472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 0 y = 20210225\n",
      "Done\n",
      "n = 1 y = 20210304\n",
      "Done\n",
      "n = 2 y = 20210312\n",
      "Done\n",
      "n = 3 y = 20210323\n",
      "Done\n",
      "n = 4 y = 20210325\n",
      "Done\n",
      "n = 5 y = 20210407\n",
      "Done\n",
      "n = 6 y = 20210412\n",
      "Done\n",
      "n = 7 y = 20210417\n",
      "Done\n",
      "n = 8 y = 20210426\n",
      "Done\n",
      "n = 9 y = 20210505\n",
      "Done\n",
      "n = 10 y = 20210506\n",
      "Done\n",
      "n = 11 y = 20210513\n",
      "ERROR2\n",
      "n = 12 y = 20210524\n",
      "Done\n",
      "n = 13 y = 20210530\n",
      "Done\n",
      "n = 14 y = 20210607\n",
      "Done\n",
      "n = 15 y = 20210610\n",
      "Done\n",
      "n = 16 y = 20210618\n",
      "Done\n",
      "n = 17 y = 20210628\n",
      "Done\n",
      "n = 18 y = 20210703\n",
      "Done\n",
      "n = 19 y = 20210709\n",
      "Done\n",
      "n = 20 y = 20210716\n",
      "Done\n",
      "n = 21 y = 20210725\n",
      "Done\n",
      "n = 22 y = 20210802\n",
      "Done\n",
      "n = 23 y = 20210808\n",
      "Done\n",
      "n = 24 y = 20210812\n",
      "ERROR2\n",
      "n = 25 y = 20210823\n",
      "Done\n",
      "n = 26 y = 20210826\n",
      "Done\n",
      "n = 27 y = 20210902\n",
      "ERROR2\n",
      "n = 28 y = 20210911\n",
      "Done\n",
      "n = 29 y = 20210916\n",
      "Done\n",
      "n = 30 y = 20210923\n",
      "Done\n",
      "n = 31 y = 20211005\n",
      "Done\n",
      "n = 32 y = 20211009\n",
      "Done\n",
      "n = 33 y = 20211018\n",
      "Done\n",
      "n = 34 y = 20211025\n",
      "Done\n",
      "n = 35 y = 20211028\n",
      "Done\n",
      "n = 36 y = 20211105\n",
      "Done\n",
      "n = 37 y = 20211111\n",
      "ERROR2\n",
      "n = 38 y = 20211123\n",
      "Done\n",
      "n = 39 y = 20211129\n",
      "Done\n",
      "n = 40 y = 20211204\n",
      "Done\n",
      "n = 41 y = 20211214\n",
      "Done\n",
      "n = 42 y = 20211216\n",
      "Done\n",
      "n = 43 y = 20211226\n",
      "Done\n",
      "n = 44 y = 20220101\n",
      "Done\n",
      "n = 45 y = 20220109\n",
      "Done\n",
      "n = 46 y = 20220116\n",
      "Done\n",
      "n = 47 y = 20220126\n",
      "Done\n",
      "n = 48 y = 20220201\n",
      "Done\n",
      "n = 49 y = 20220207\n",
      "Done\n",
      "n = 50 y = 20220211\n",
      "Done\n",
      "n = 51 y = 20220222\n",
      "Done\n",
      "n = 52 y = 20220224\n",
      "ERROR2\n",
      "n = 53 y = 20220307\n",
      "ERROR2\n",
      "n = 54 y = 20220310\n",
      "Done\n",
      "n = 55 y = 20220317\n",
      "Done\n",
      "n = 56 y = 20220324\n",
      "ERROR2\n",
      "n = 57 y = 20220404\n",
      "ERROR2\n",
      "n = 58 y = 20220410\n",
      "Done\n",
      "n = 59 y = 20220416\n",
      "Done\n",
      "n = 60 y = 20220421\n",
      "Done\n",
      "n = 61 y = 20220502\n",
      "Done\n",
      "n = 62 y = 20220507\n",
      "Done\n",
      "n = 63 y = 20220518\n",
      "ERROR2\n",
      "n = 64 y = 20220523\n",
      "Done\n",
      "n = 65 y = 20220529\n",
      "Done\n",
      "n = 66 y = 20220608\n",
      "ERROR2\n",
      "n = 67 y = 20220615\n",
      "ERROR2\n",
      "n = 68 y = 20220616\n",
      "ERROR2\n",
      "n = 69 y = 20220629\n",
      "ERROR2\n",
      "n = 70 y = 20220630\n",
      "ERROR2\n",
      "n = 71 y = 20220708\n",
      "Done\n",
      "n = 72 y = 20220719\n",
      "Done\n",
      "n = 73 y = 20220725\n",
      "ERROR2\n",
      "n = 74 y = 20220802\n",
      "Done\n",
      "n = 75 y = 20220808\n",
      "ERROR2\n",
      "n = 76 y = 20220811\n",
      "Done\n",
      "n = 77 y = 20220819\n",
      "ERROR2\n",
      "n = 78 y = 20220830\n",
      "ERROR2\n",
      "n = 79 y = 20220905\n",
      "Done\n",
      "n = 80 y = 20220911\n",
      "Done\n",
      "n = 81 y = 20220918\n",
      "Done\n",
      "n = 82 y = 20220926\n",
      "ERROR2\n",
      "n = 83 y = 20221004\n",
      "ERROR2\n",
      "n = 84 y = 20221006\n",
      "Done\n",
      "n = 85 y = 20221015\n",
      "ERROR2\n",
      "n = 86 y = 20221025\n",
      "ERROR2\n",
      "n = 87 y = 20221030\n",
      "Done\n",
      "n = 88 y = 20221103\n",
      "ERROR2\n",
      "n = 89 y = 20221115\n",
      "Done\n",
      "n = 90 y = 20221117\n",
      "ERROR2\n",
      "n = 91 y = 20221129\n",
      "Done\n",
      "n = 92 y = 20221203\n",
      "Done\n",
      "n = 93 y = 20221213\n",
      "ERROR2\n",
      "n = 94 y = 20221219\n",
      "Done\n",
      "n = 95 y = 20221228\n",
      "ERROR2\n",
      "n = 96 y = 20221230\n",
      "Done\n",
      "n = 97 y = 20230109\n",
      "Done\n",
      "n = 98 y = 20230117\n",
      "Done\n",
      "n = 99 y = 20230125\n",
      "Done\n",
      "n = 100 y = 20230129\n",
      "Done\n",
      "n = 101 y = 20230204\n",
      "Done\n",
      "n = 102 y = 20230209\n",
      "Done\n",
      "n = 103 y = 20230220\n",
      "Done\n",
      "n = 104 y = 20230227\n",
      "Done\n",
      "n = 105 y = 20230302\n",
      "ERROR2\n",
      "n = 106 y = 20230310\n",
      "ERROR2\n",
      "n = 107 y = 20230316\n",
      "Done\n",
      "n = 108 y = 20230323\n",
      "Done\n",
      "n = 109 y = 20230404\n",
      "Done\n",
      "n = 110 y = 20230411\n",
      "Done\n",
      "n = 111 y = 20230417\n",
      "Done\n",
      "n = 112 y = 20230420\n",
      "Done\n",
      "n = 113 y = 20230428\n",
      "Done\n",
      "n = 114 y = 20230510\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for n, y in e:\n",
    "    print(\"n =\", n, \"y =\", y)\n",
    "    url = \"https://news.naver.com/main/ranking/popularDay.naver?date=\" + y\n",
    "    headers = {'User-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "    html = requests.get(url, headers = headers, timeout = 5)\n",
    "    #time.sleep(5)\n",
    "\n",
    "    bs_obj = bs4.BeautifulSoup(html.content, \"html.parser\")\n",
    "    div = bs_obj.findAll(\"div\", {\"class\":\"rankingnews_box\"})\n",
    "\n",
    "    k=1\n",
    "    data=[]\n",
    "    col = ['No','Publisher','Rank','Title','URL']\n",
    "\n",
    "    for i in div:\n",
    "        publisher = i.find(\"strong\", {\"class\":\"rankingnews_name\"})\n",
    "        if publisher.text in check:\n",
    "            ul = i.find(\"ul\", {\"class\":\"rankingnews_list\"})\n",
    "            lis = ul.findAll(\"li\")\n",
    "            for j in lis:\n",
    "                em_tag = j.find(\"em\")\n",
    "                a_tag = j.find(\"a\")\n",
    "\n",
    "                if (a_tag != None) and (em_tag != None):\n",
    "                    article_url = a_tag['href']\n",
    "                    row = [k, publisher.text, em_tag.text, a_tag.text, article_url]\n",
    "                    data.append(row)\n",
    "                    k += 1\n",
    "#                    news=urllib.request.urlopen(article_url)\n",
    "#                    news_obj = bs4.BeautifulSoup(news, \"html.parser\")\n",
    "#                     body = news_obj.find(\"div\", {\"id\":\"newsct_article\",\"class\":\"newsct_article _article_body\"})\n",
    "#                     if body == None:\n",
    "#                         body = news_obj.find(\"div\", {\"id\":\"newsEndContents\",\"class\":\"news_end\"})\n",
    "#                         print(\"newsEnd\")\n",
    "#                         if body == None:\n",
    "#                             print('ERROR1')\n",
    "#                             continue\n",
    "#                     contents = body.text.replace('\\n','')\n",
    "#             time.sleep(random.randint(1, 4))\n",
    "#         time.sleep(random.randint(1, 4))\n",
    "\n",
    "    df = pd.DataFrame(data, columns = col)\n",
    "    df.to_csv('D:/marketing/data7/df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR2\")\n",
    "        error.append(0)\n",
    "    else:\n",
    "        print(\"Done\")\n",
    "        error.append(1)\n",
    "#     time.sleep(10)\n",
    "\n",
    "#     text = df[df['Publisher'].isin(check)]['Contents']\n",
    "#     text_filtered = text.str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\" \")\n",
    "\n",
    "#     #time.sleep(5)\n",
    "\n",
    "#     tokenized_data_filtered=[]\n",
    "#     for j in text_filtered:\n",
    "#         temp = tagger.nouns(j)\n",
    "#         temp = [word for word in temp if len(word)>1]  ## 두글자 이상이면 포함, 리스트 함축\n",
    "#         temp = [word for word in temp if word not in stopwords]\n",
    "#         tokenized_data_filtered.append(temp)\n",
    "\n",
    "#     #time.sleep(5)\n",
    "\n",
    "#     tokens=[]\n",
    "#     for k in tokenized_data_filtered:\n",
    "#         tokens.extend(k)\n",
    "\n",
    "#     #time.sleep(5)\n",
    "\n",
    "#     num_top_tokens=100\n",
    "#     counted_tokens=Counter(tokens)\n",
    "#     top_keywords=dict(counted_tokens.most_common(num_top_tokens))\n",
    "\n",
    "#     #time.sleep(5)\n",
    "\n",
    "#     tk_df = pd.DataFrame(list(top_keywords.items()), columns=['keywords','freq'])\n",
    "#     tk_df.to_csv('D:/marketing/data5/tk_df' + str(n) + '.csv', encoding = 'utf-8-sig')\n",
    "#     print(\"sleep 10min\")\n",
    "#     time.sleep(600)\n",
    "#     t = random.randint(30, 60)\n",
    "#     time.sleep(t)\n",
    "#     print('#'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7493dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e899519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "24\n",
      "27\n",
      "37\n",
      "52\n",
      "53\n",
      "56\n",
      "57\n",
      "63\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "73\n",
      "75\n",
      "77\n",
      "78\n",
      "82\n",
      "83\n",
      "85\n",
      "86\n",
      "88\n",
      "90\n",
      "93\n",
      "95\n",
      "105\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(error):\n",
    "    if i == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2454c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
